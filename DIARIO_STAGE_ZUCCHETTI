lunedi 20 maggio

1 SETTIMANA
- studio documentazione ConvNet.js (https://cs.stanford.edu/people/karpathy/convnetjs/): Getting started, Documentation, intro
- ricerca su github progetto reti neurali con uso della libreria ConvNet (da terminare);
- inzio studio problema delle coppie di eventi (A,B domande);
  A e B eventi indipendenti, A e B eventi dipendenti, evento A conosciuto comporta la conoscenza dell'evento B (cio' non implica il contrario), Odds Ratio, probabilita' di evento conosciuto e indovinato (da portare il latex in data 21 maggio).

martedi 21 maggio
- studio, rielaborazione, stesura in latex problema delle coppie, eventi dipendenti/eventi indipendenti, probabilita' per un candidato di dare la risposta corretta ad una domanda durante un test (analisi_dati.zip);
- discussione rappresentazione su piano probabilita' di ottenere una risposta corretta ad una domanda (P(A)).

mercoledi 22 maggio 
- continuazione studio e stesura documento latex con trattazione della rappresentazione di P(A) su un piano nelle 3 dimensioni s0,s1,s2 con studio, argomentazioni di esempi e rappresentazione degli stessi mediante grafici in 2d;
- inizio costruzione modello P(A) in 3d. Fissati gli assi cartesiani s0, s1 e s2 (aiuto tutor).


giovedi 23 maggio
- studio libreria ConvNet.js con implementazione scheletro rete neurale con addestramento;
- continuazione modello in 3d. Fissate le rette s2=1-s1 sulle tre dimensioni con conseguente formazione di un triangolo equilatero sul piano (aiuto tutor).

venerdi 24 maggio
- inizio implementazione nuova rete neurale sulla base di uno spazio di input e output di dimesione 6.
 L'input rappresenta il vettore del numero di domanda [1,2,3..]; l'otput rappresenta un vettore con tanti valori quanto e' la dimensione del vettore in input e un valore e' uno tra -1(risposta sbagliata), 0(risposta non data) e 1(risposta esatta) [1,0, 0, -1]. Il fine sara' addestrare la rete a comprendere se un candidato sapra' rispondere o meno, sulla base dei test di addestramento, a una specifica domanda

2SETTIMANA
lunedi 27 maggio
- continuo sviluppo rete neurale: sistemati box (a numerosita' dinamica) per l'emissione dei dati di input e di output, creati bottoni e form per il trainer dei dati e la previsione, implementazione metodi di update (per il trainer) e prevision, documentazione e commento del codice.

martedi 28 maggio
- continuazione sviluppo rete neurale con preparazione del box di log nell'applicativo;
- rilettura documentazione correzione errori sul documento "Analisi dei dati di probabilita'"
- testata la rete con i primi test (banali);
- presentazione della rete al tutor aziendale (richiesta ristrutturazione della stessa che deve avvera'  durante i prossimi giorni. I dati alla rete verranno passati gia' normalizzati causa la necessita', altrimenti, di un tempo troppo elevato di apprendimento della stessa)
- Proseguito con il modellino di P(A)

mercoledi 29 maggio
- ristrutturazione della rete con implementazione dell'autoencoder e del metodo di previsione;
- costruiti test di dimensione 6 per testare la bonta' dell'apprendimento, seguendo un grafo logico, prima manualmente (i primi 30), e a seguito di un'analisi dei risultati da cui e' stata riscontrata un' oscillazione delle previsioni si e' deciso di procedere all'implementazione di un metodo (1a versione) di generazione automatica dei vettori di training in modo da far apprendere in massa la rete ed evitare cosi' tali oscillazioni
- Proseguito con il modellino di P(A)


giovedi 30 maggio
- implemetazione del metodo di generazione automatica dei vettori di training medainte un metodo che tiene conto anche della probabilita' che un candidato ha di dare la risposta esatta (P(A) risultante dalla 1a settimana di stage)
- Analisi dei dati di previsione ottenuti con le diverse generazioni di array
- Ritocchi interfaccia: sistemato vettore di inserimento previsione e concessa la possibilita' di inserimento del vettore direttamente da interfaccia
- Separazione del file function in un file per ogni metodo implementato,

venerdi 31 maggio
- continuazione esecuzione dei test sulla rete neurale a 6 dimensioni;
- Ritocchi all'interfaccia (tolto il bottone di change).
- redazione di una breve sulle osservazioni riscontrare durante i test.


3 SETTIMANA
lunedi 3 giugno
- documentato e ottimizzato codice del rete di test
- documentato e continuata documentazione "Reti neurali" in base al codice ottimizzato
- create funzione createJSON con lo scopo di estrapolare il JSON della rete con i pesi
- inizio sviluppo metodo per normalizzare i test del db

martedi 4 giugno
- continuzione e termine metodo di normalizzazione (function normalizationVectorTest) per la creazione dei vettori di training del db
- montaggio rete neurale a 89 dimensioni: configurazione, addestramento e pevisione (utilizzo come training di apprendimento il file 'risposte_logica_liv1.csv')

mercoledi 5 giugno
 - perfezionamente stile grafico dell'interfaccia per la rete db (colori pulsanti update e write document, ampliata la dimensione dei box che mostra la configurazione e le operaioni della rete sul css)
- lavorato sul metodo writedocument: paginetta che stila i dati di training della rete di prova
- sviluppo  funzionalita' canvas di risposta alle domande con diversi colori in base alla previsione nella rete di prova (aggiunto anche alla rete del db)
- implementato il metoodo normalizatioVectorTestPivoting che fornisce i vettori di training partendo da un file csv ottimale (risposte_logica_liv1_pivot.csv')
- continuazione documentazione test con diversi vettori di previsione (es [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]) per la rete di prova

giovedi 6 maggio
 - continuazione test su rete neurale di prova e correzione bug

venerdi 7 maggio
 - trovato bug nel metodo update (passavo all'apprendimento un vettore alla volta, quando invece e' indispensabile avere un batch), ridefinita l'interfaccia della rete di prba (ottimizzata e tolti componenti aggiuntivi come bottone di train, box di input)
- montata e configurata rete neurale del db
- stesa sezione documentazione test rete finale di prova
- effettuati test con diverse combinazioni di vettori di previsione e configurazione sulla rete di prova
- ritoccato metodo che miscela dei colori (vedere se con l'avanzamento del lavoro la differenziazione e' sufficiente)
- inizio primi test sulla rete del db

4 SETTIMANA
lunedi 10 maggio
- sviluppata funzionalita' (sia nella rete di prova che del db) che mostra l'impatto che ogni elemento del vettore previsione ha sulla sua rispettiva domanda e come oscillano le restanti n-1. Modificati i rispettivi css e incorportati i metodi animationPrevision_detail e prevision_singleElement

martedi 11 maggio
- controllo del codice prodotto (rete neurale di prova e db) e ottimizzazione delle funzioni  normalizationVectorTestPivot(), normalizationVectorTest_standard() con eliminazione variabile globale var Test
- stesa documentazione per test con dettaglio delle previsioni sulla rete di prova, e valutate previsioni al dettaglio sulla rete del database con diverse architetture (riscontrata per maggiore chiarezza dei risultati raggiunti la necessita' di creare un cluster dei dati)

- mercoledi 12 maggio
sviluppo metodo cluster che permette di infividuare le coppie di domande in relazione stretta tra di loro, all'interno della rete
- test su diverse architetture della rete , usando la funzione cluster, per studiare i comportamenti della stessa.

lunedi 17 giugno
- Studio di R e delle tecnica di PCA 
- Configurazione ambiente di lavoro (installazione di R ed R studio che offere una console user-friendly e scelta dei package da utilizzare per lo sviluppo - oltre cio' che offre la libreria standard di R anche library(factoextra) che permette l'uso di plot e calcoli dei autovalori/autovettori) e Implementazione per la PCA per la rete di prova

martedi 18 giugno
- Approfondimento studio della tecnica di PCA (sia dal punto di vista matematico che implementativo)
- organizzazione dei file csv da dare in pasto allo script R
- Analisi del codice redatto il giorno precedente e trasposizione del codice sviluppato per la i dati della rete di prova sui dati della rete del db

5 SETTIMANA

mercoledi 19 giugno
- continuazione sviluppo dello script PCA per i dati del db e la rete neurale

giovedi 20 giugno
- studio possibilita' di inserire i test d'unita nel codice js, implementati test d'unita' per moduli generator_input e generator_input_probability (2)
- analisi domande del database, confrontate con i risultati ottenuti dalla pca e dalla rete neurale

venerdi 21 giugno
- continuazione studio dei risultati ottenuti dalla rete neurale e dalla PCA con connfronto con la descrizione delle domande del db. Sviluppato metodo di previsione per la PCA
- implementati test d'unita' sul modulo cluster (2)
 
lunedi 24 giugno

- controllo codice completo dei modello di analisi costruiti per i dati di prova e per i dati delle domande presenti nel database aziendale
- documentazione tecnica di PCA e presentazione del modello

martedi 25 giugno
- creazione radio box dinamica per il vettore di previsione delle domande
- inizio studio libreria D3.js per poter rappresentare il Reticolo della Conoscenza delle domande

6 SETTIMANA

mercoledi 26 settembre
- traslazione da D3.js a "Reticolo della Conoscenza" costruito con la tesi di Matteo
- costruzione del metodo vettore_Reticolo che prepara i dati da dare in pasto al Reticolo della Conoscenza
- Test sul Reticolo della Conoscenza creato mediante previsioni e delta della Rete
- Rilettura documentazione parte inerente alla Probabilita' della domanda
- Valutazione possibilita' di avere altri test d'unita' (non andata a buon fine)
- creato file CSV che contiene il delta di previsioni per un architettura a 2 layers con 8 neuroni ciascuno

giovedi 27 settembre
- revisionata e riletta documentazione sulla PCA (dato anche un breve sguardo a quanto scritto per la sezione sulla Rete Neurale)
- creati due nuovi test (#Test4) d'unita che testano il comportamento del modulo configure e configure_db: per farlo ho rivisto se nel codice fosse possibile eliminare alcune variabili globali
- creato file CSV che contiene il delta di previsioni per un architettura a 2 layers con 12 neuroni ciascuno
