\section{Rete neurale}
\label{Rete neurale}

La libreria utilizzata per sviluppare la Rete neurale \`e stata \textit{ConvNetJS}. L'aspetto positivo di tale scelta \`e stata la semplicit\`a nell'utilizzo del linguaggio javascript; l'aspetto negativo ha riguardato la totale mancanza di mantenibilit\`a della libreria stessa che comporta la scarsit\`a di esempi applicativi, oltre alla documentazione ufficiale, che costringono lo sviluppatore ad una ricerca approfondita personale in un ambiente ove lo nozioni si presentano scarse e a continue prove per verificare la validit\`a del codice prodotto.
\begin{figure}[H]
\centering
	\includegraphics[width=1\linewidth]{./image/GUI-rete-neurale.png}
	\caption{Interfaccia utente della Rete neurale di prova.}
\end{figure}
\noindent
Durante il periodo 24/05 - 31/05 mi sono occupata dello sviluppo di una Rete neurale in grado di ricevere in input un training set di dimensione 6 e di restituire una previsione sui dati di apprendimento ricevuti.
\noindent
Il problema che la rete mira ad analizzare \`e quello discusso nel precedente capitolo \textit{Analisi dei dati di probabilit\`a}
\\\\
Per aggevolare l'apprendimento della rete, ed ottenere delle previsioni stabili mi sono occupata di implementare due metodi di generazione randomica di dati in modo da far apprendere massiciamente la stessa.
Il dato prodotto consiste in un vettore di 6 elementi, composto da  -1, 0 e 1 con il seguente criterio:
\begin{itemize}
\item \textbf{-1}: la domanda x \`e stata posta al candidato che ha risposto in maniera errata;
\item \textbf{0}: la domanda x non \`e stata posta al candidato;
\item \textbf{1}: la domanda x \`e stata posta al candidato che ha saputo rispondere correttamente.
\end{itemize}
\noindent
Il primo metodo che ho sviluppato si occupa di generare un vettore di dati di apprendimento basandosi esclusivamente su come le domande sono interconnesse tra di loro (grazie all'uso di un grafo della conoscenza costruito ad hoc); il secondo metodo ripropone quanto perseguito dal primo metodo con il valore aggiunto di generazione di un profilo randomico di un candidato, che tiene conto della  probabilit\`a di risposta ad una domande seguendo la formula P(A)= $\frac{1}{3}+\frac{1}{6}P(S_1)+\frac{2}{3}P(S_2)$.

\subsection{Test effettuati}
\label{Test effettuati}

Alcune decisioni che ho preso durante la configurazione della rete riguardano i seguenti settori:
\begin{enumerate}
\item Una rete neurale non deve, per fornire dei dati attendibili, possedere un numero di neuroni troppo elevato rispetto al trainset effettuato; altrimenti la previsione  ritornerebbe l'identit\`a del vettore di input della stessa, come conseguenza diretta della capacit\`a troppo elevata di immagazzinare dati.
\item I layers, ho deciso, di allenarli mediante tecnica di regressione, che permette l'inserimento in input di una funzione obiettivo e l'ottenimento di un risultato, in output, anche in virgola mobile e composto di tanti elementi quanti sono i neuroni di regressione dichiarati. Per la mia rete di prova \`e necessario dichiarare  6 neuroni in regressione perch\`e l'output, appunto, che ci si aspetta dal sistema \`e di 6 elementi.
\item Per costruire un dataset di dati consistente che permettesse alla rete di imparare qualcosa ho costruito un grafo della conoscenza con lo scopo di mettere in relazione degli argomenti che coinvolgono uno o pi\`u domande.
\begin{figure}[H]
\centering
	\includegraphics[width=0.60\linewidth]{./image/grafo_trainset.png}
	\caption{Grafo rappresentante le relazioni esistenti tra il set di domande di prova.}
\end{figure}
\noindent
Per svolgere l'apprendimento ogni vettore, facente parte del dataset, viene dato in pasto alla rete che a sua volta provvede alla sua assimilazione come conoscenza mediante la tecnica dell'autoencoder, ovvero la rete impara il vettore riducendone lo spazio occupato.
\item Per creare il dataset ho ritenuto sufficiente generare \textit{2000} vettori di risposta in modo da compiere in maniera esaustivo l'apprendimento della rete.
\end{enumerate}
\noindent
Il vettore passato in input per svolgere le previsioni \`e \textit{[0,1,0,0,0,0]}\\
\noindent. 
Di seguito riporto quanto \`e stato rilevato in fase di test.

\subsubsection{Configurazione della rete: 4 neuroni per ciascuno dei 2 layers}
\label{Configurazione della rete: 4 neuroni per ciascuno dei 2 layers}

Configurazione della rete utilizzata:\\
\begin{verbatim}layer_defs = [];
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:6});
layer_defs.push({type:'fc', num_neurons:4, activation: 'tanh'});
layer_defs.push({type:'fc', num_neurons:4, activation: 'tanh'});
layer_defs.push({type:'regression', num_neurons:6});

net = new convnetjs.Net();
net.makeLayers(layer_defs);

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01,
 momentum:0.1, batch_size:10, l2_decay:0.001});
\end{verbatim}
\noindent
I layers utilizzati sono 2 e compositi da 4 neuroni.

\paragraph{Training set standard a 4 neuroni per ciascuno dei 2 layers}\mbox{}
\label{Training set standard a 4 neuroni per ciascuno dei 2 layers}
\\
\noindent
\begin{itemize}
\item \begin{verbatim}[-0.023855333986977867,0.1208682137075327,0.4260345380634862,
0.0722560576473409,0.3283088623731066,-0.17618850480783232] \end{verbatim}
Appaiono in relazione le domande 2, 3, 4, 5 e 1, 6.\\
Gli scostamenti tra le coppie 2 e 5, 1 e 4, 3 e 6 non sono consistenti con quelle che sono le relazioni di dipendenza,\`e una differenza che parte da qualche millesimo fino 0.5 circa; che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4; nel test in analisi questo non vale per la domanda 1 e 4 in relazione con la domanda 3 per una differenza che ancora parte da qualche millesimo fino a 0.5 circa, invece negli altri casi si \`e conformi a tale regola.

\item \begin{verbatim}[-0.03806810786701341,0.019541611557198593,0.09925138445700073,
-0.13079207557949227,0.15276826195250218,-0.12170966930647197] \end{verbatim}\\
Appaiono in relazione le domande 1, 4, 6 e 2, 3, 5.\\
Gli scostamenti tra le coppie 1 e 4, 2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per quanto concerne la coppia 3 e 6 vi \`e una differenza minima dello 0.2, dovuta dalla presenza di -1  all'interno dei vettori di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4; nel test in analisi questo non vale per la domanda 1 e 4 in relazione con la domanda 3 per una differenza che ancora parte da qualche millesimo fino a 0.1 circa e ancora nel rapporto tra; la domanda 6 e 3; ma per una differenza trascurabile.

\item \begin{verbatim}[0.2775515957162251,0.057230274521780505,-0.24457944139408838,
-0.20011414460676974,0.16097406009656845,-0.18554952190813764]\end{verbatim}\\
Appaiono in relazione le domande 1, 2, 5 e 3, 4, 6.\\
Gli scostamenti tra le  coppie 3, 6 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per quanto concerne le coppia 1, 4 vi \`e una differenza attorno allo 0.5; che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4; nel test in analisi solo la domanda 4 in confronto con la domanda 3 non rispetta la regola per un valore trascurabile attorno allo 0.04.

\item \begin{verbatim}[-0.05590408530030894,0.36601350994521475,0.6540111916765196,
0.3243649420532155,0.3017867247551915,-0.009890881575641955]\end{verbatim}
Appaiono in relazione 1, 6 e 2, 3, 4, 5.\\
Gli scostamenti tra le coppie 2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per quanto concerne le coppie 1, 4 e 3, 6 vi \`e una differenza attorno allo 0.3 - 0.6 circa; che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4; nel test in analisi solo la domanda 3 in confronto con la domanda 6 rispetta la regola, negli altri casi la differenza oscilla attorno allo 0.3 - 0.6.
\end{itemize}


\paragraph{Training set con generazione del profilo di un candidato e calcolo delle probabilit\`a di risposta a 4 neuroni per ciascuno dei 2 layers}\mbox{}
\label{Training set con generazione del profilo di un candidato e calcolo delle probabilita di risposta a 4 neuroni per ciascuno dei 2 layers}
\\
\noindent
\begin{itemize}
\item  \begin{verbatim}[-0.03737583291545811,0.05724010616361251,0.44784260178601065,
0.3036299097749936,-0.06323778881822914,0.005856204303387735]
\end{verbatim}
Appaiono in relazione le domande 1, 5 e 2, 3, 4, 6.\\
La coppia 1, 4 non sono \`e in relazione stretta con una differenza dello 0.3 circa. La domanda  sia 1 che 4 presentano una positivit\`a inferiore rispetto alla domanda sia 3 che 6 non mostrandosi cos\`i conforme alla regola per una differenza attorno a qualche millesimo fino a 0.4, invece la domanda 4 risulta conforme. L'anomalia pu\`o venire ricondotta all'uso di un set con dati "spuri", calcolati mediante la probabilit\`a che un candidato ha di rispondere correttamente o meno ad una i-esima domanda (tale formula ha fatto venire meno la validit\`a parziale delle relazioni che intercorrono tra le domande) che alla presenza dei valori -1 del vettore di training. Il secondo fattore per\`o ha sicuramente un influenza inferiore rispetto al primo sui risultati ottenuti.

\item \begin{verbatim}[0.20419725210796835,0.5253075230531483,0.2901462190639711,
-0.31178174432530004,-0.062048680652950994,0.5148356351092167]

\end{verbatim}
Appaiono in relazione le domande 1, 2, 3, 6 e 4, 5.\\
La coppia 2, 5 non \`e pi\`u in relazione stretta ma con una differenza di qualche millesimo; questo non vale per le coppie 2, 5 e 1, 4 che rimangono conformi alla regola. Solo le domanda 4 in rapporto con la domanda 6 si mostra con una positivit\`a superiore conforme alla regola, negli altri casi le differenza arriva fino a 0.3.

\item  \begin{verbatim}[0.012721245506408296,0.40018653532722875,-0.2178035851783261,
-0.24848647653037334,0.4034153755408919,-0.14390378560537195]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 4 e  3, 5, 6.\\
La coppia 2, 5 non \`e pi\`u in relazione stretta ma con una differenza importante che oscilla attorno allo 0.6 circa. La domanda 1 presenta una positivit\`a superiore rispetto alla domanda alla 3 e 6, mostrandosi  conforme alla regola; invece la domanda 4 ha una differenza  attorno allo 0.1. L'anomalia pu\`o venire ricondotta all'uso di un set con dati "spuri"  usati per effettuare il training degli stessi.

\item  \begin{verbatim}[0.5381900630756038,0.21501287122177454,-0.025937803643848664,
-1.020445268637535,-0.11434978729682023,-0.0036717206684206416]
\end{verbatim}
Appaiono in relazione le domande 1, 2 e 3, 4, 5, 6.\\
Le domanda 1 ,4 e 3, 6  sono in relazione stretta, questo non vale per la coppia 2, 5 che ha una differenza circa dello 0.3. La domanda 4 presenta una positivit\`a inferiore rispetto alla domanda sia 3 che 6 con una differenza attorno ad 1 unit\`a presentandosi non conforme alla regola; invece la domanda 1 risulta conforme alla regola. L'anomalia pu\`o venire ricondotta all'uso di un set con dati "spuri" usati per il effettuare il training degli stessi.
\end{itemize}

\paragraph{Osservazioni}\mbox{}
\label{Osservazioni su rete a 4 neuroni per ciascuno dei 2 layers}
\\\\
\noindent
La configurazione testata si compone di 4 neuroni a layer su una base di 2000 test correndo il rischio di avere una rete che apprende troppo e come effetto negativo "veda" addirittura cose che non esistono.\\
Per fare un 'ulteriore verifica del sistema da me sviluppato ne ho mutato la configurazione riducendo il numero di neuroni presenti in ciascun layers e/o il numero di layers presenti.\\
Le nuove configurazione su cui ho effettuato i test sono esposte nei paragrafi seguenti.

\subsubsection{Configurazione della rete a 2 neuroni per ciascuno dei 2 layers}
\label{Configurazione della rete a 2 neuroni per ciascuno dei 2 layers}
Configurazione della rete utilizzata:\\
\begin{verbatim}layer_defs = [];
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:6});
layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});
layer_defs.push({type:'fc', num_neurons:2, activation: 'tanh'});
layer_defs.push({type:'regression', num_neurons:6});

net = new convnetjs.Net();
net.makeLayers(layer_defs);

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01,
 momentum:0.1, batch_size:10, l2_decay:0.001});
\end{verbatim}
\noindent
I layers utilizzati sono 2 compositi da 2 neuroni.

\paragraph{Training set standard su rete a 2 neuroni per ciascuno dei 2 layers}\mbox{}
\label{Training set standard su rete a 2 neuroni per ciascuno dei 2 layers}
\\
\noindent
\begin{itemize}
\item \begin{verbatim}[0.2794527428464376,-0.2802484238110681,0.3381473085717851,
0.4998270008990551,-0.24101715255148007,0.2582029386344382]\end{verbatim}
Appaiono in relazione le domande 1, 3, 4, 6  e 2, 5.\\
Gli scostamenti tra le coppie  1 e 4, 3 e 6,  2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata nel caso della domanda 4 che supera di netto la frequenza di 3 e 6; poco male per la domanda 1 che supera esclusivamente la domanda 6; ma la differenza con la frequenza della domanda 3 sta nell'ordine di millesimi da poter associare ad alterazioni dovute alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim}[-0.12075039921729117,-0.14296107416878934,0.07982069495440205,
0.011104331627748144,0.1470292747196045,0.09606910379911124]\end{verbatim}
Appaiono in relazione le domande 1, 2 e 3, 4, 5, 6.\\
Gli scostamenti tra le coppie 3, 6 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 1, 4 e 2, 5 i segni sono opposti con una differenza tuttavia trascurabile  che oscilla tra lo 0.1 e lo 0.2, che posso far ricondurre la alla presenza dei valori -1 nel vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata sia dalla domanda 6 che 3; ma la differenza sta nell'ordine di millesimi da poter associare ad alterazioni dovute alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim}[0.02780722943834754,0.2723440329274166,0.12188698314538576,
0.1458902079749947,0.03212236455933414,-0.20192205192242818]
\end{verbatim}
Appaiono in relazione le domande 1, 4, 2, 3, 5 e 6 (a parte).\\
Gli scostamenti tra le coppie 1, 4 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 3, 6 i segni sono opposti con una differenza tuttavia trascurabile  che oscilla attorno lo 0.3, che posso far ricondurre la alla presenza dei valori -1 nel vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata solo tra le domande 1 e 3 ma per una differenza trascurabile dello 0.1.

\item \begin{verbatim}[-0.08376630404558708,0.12067533185697796,0.1491004665909827,
-0.49836156676824916,0.012724718506561317,-0.4107879429368803]
\end{verbatim}
Appaiono in relazione le domande 1, 4, 6 e 2, 3, 5.\\
Gli scostamenti tra le coppie 1, 4 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 3 e 6 i segni sono opposti con una differenza  attorno allo 0.6.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene non rispettata dalla domanda 3 nei confronti della domanda 1 e 4 e per la domanda 6 nei confronti con la domanda 4; ma in ogni caso la differenza \`e marginale  essendo coinvolgere la domanda 3 e posso sempre ricondurla ad oscillazioni della rete.
\end{itemize}


\paragraph{Training set con generazione del profilo di un candidato e calcolo delle probabilit\`a di risposta a 2 neuroni per ciascuno dei 2 layers}\mbox{}
\label{Training set con generazione del profilo di un candidato e calcolo delle probabilita di risposta a 2 neuroni per ciascuno dei 2 layers}
\\
\noindent
\begin{itemize}
\item \begin{verbatim}[0.0014939473221869328,0.00008866264558449942,-0.0051039572299997425,
-0.020202729539546355,0.009480113116598188,0.0018674039920875888]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 5, 6  e 3, 4.\\
Gli scostamenti tra la coppia 2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 1, 4 e 3, 5 i segni sono opposti con una differenza tuttavia trascurabile inferiore al millesimo.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata nel caso della domanda 1 che supera la frequenza di 3 e 4, poco male perch\`e la differenza \'e trascurabile inferiore al millesimo, da poter associare ad alterazioni dovute alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim}[0.544465180879028,0.30741483494259525,-0.05978298930333867,
0.07618785219787755,0.20828694965540176,0.28254321048406633]
\end{verbatim}
Appaiono in relazione le domande 1, 2,  4, 5, 6 e 3 (a parte)\\
Gli scostamenti tra le coppie 1, 4 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 3, 6 i segni sono opposti con una differenza dello 0.3, che posso far ricondurre la alla presenza dei valori -1 nel vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata dalla domanda 4 in rapporto con 3; ma la differenza sta sempre nell'ordine dei millesimi da poter associare ad alterazioni dovute alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim}[0.1910638695115555,0.000591429229778241,0.03066702296109937,
0.08222365813985216,0.007067502425449214,-0.013488907175148557]
\end{verbatim}
Appaiono in relazione le domande 1, 4, 2, 3, 5 e 6 (a parte).\\
Gli scostamenti tra le coppie 1, 4 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per la coppia 3, 6 i segni sono opposti con una differenza tuttavia trascurabile  che oscilla attorno all'ordine dei millesimi, che posso far ricondurre alla alla presenza dei valori -1.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata pienamente.

\item \begin{verbatim}[0.06749554602043151,-0.5960274542125068,-0.29293270738073995,
-0.887419364280586,1.0148867009493885,0.8353342224531083]
\end{verbatim}
Appaiono in relazione le domande 1, 5, 6 e 2, 3, 4.\\
Gli scostamenti tra le coppie 1 e 4, 2 e 5, 3 e 6 non sono consistenti con quelle che sono le relazioni di dipendenza fra le domande i segni sono opposti con una differenza trascurabile attorno a qualche millesimo fino a 0.7. 
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata  esclusivamente nel rapporto tra le domande 3 e 4; con differenza \`e che va dallo 0.7 fino ad 1 unit\`a.
\end{itemize}


\paragraph{Osservazioni}\mbox{}
\label{Osservazioni su rete a 2 neuroni per ciascuno dei 2 layers}
\\\\
\noindent
Confrontando i risultati ottenuti dalla rete con i layers impostati a 4 neuroni con quanto emerso dai dati risultanti dalla  rete a 2 neuroni, posso dire che sia nel caso di Training set standard che con generazione di profilo del candidato la situazioni, rispetto ai valori attesi, nel secondo gruppo di test sembra essere migliore.\\
Emerge nel training standard una previsione che rispecchia pi\`u uniformemente il grafo della conoscenza utilizzato, a prova di ci\`o  \`e ii set dei dati completamente conforme con le aspettative, a meno di errori di millesimi trascurabili. Tale effetto \`e meno evidente quando al set viene applicata la formula della probabilit\`a di una domanda perch\`e i dati, rispetto al grafo, vengono "sporcati"; ma comunque le coppie che risultano ancora tali e la frequenza che vincola le domande dell'insieme A con quelle dell'insieme B rimangono di una precisione superiore rispetto alla prima configurazione della rete.


\subsubsection{Configurazione della rete a 4 neuroni per 1 layer}
\label{Configurazione della rete a 4 neuroni per 1 layer}

Configurazione della rete utilizzata:\\
\begin{verbatim}layer_defs = [];
layer_defs.push({type:'input', out_sx:1, out_sy:1, out_depth:6});
layer_defs.push({type:'fc', num_neurons:4, activation: 'tanh'});
layer_defs.push({type:'regression', num_neurons:6});

net = new convnetjs.Net();
net.makeLayers(layer_defs);

trainer = new convnetjs.SGDTrainer(net, {learning_rate:0.01,
 momentum:0.1, batch_size:10, l2_decay:0.001});
\end{verbatim}
\noindent
Viene utilizzato un unico layer da 4 neuroni.

\paragraph{Training set standard su rete a 4 neuroni per 1 layer}\mbox{}
\label{Training set standard su rete a 4 neuroni per 1 layer}
\\
\noindent
\begin{itemize}
\item \begin{verbatim}[0.4123183944220304,0.23559132912257008,-0.32336199925385695,
-0.5153315695275302,0.15431093203893884,0.2926326097414193]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 5, 6 e 3, 4\\
Gli scostamenti tra la coppia 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande; invece per le coppia 3, 6 e 1, 4 i segni si presentano con una differenza che va dallo 0.5 allo 0.9, che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training. 
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata nel caso della domanda 1; ma la regola viene sfasata dalla domanda 4 con una differenza oscilla tra lo 0.7 e lo 0.9, che mi sembra eccessiva se fatta risalire solo alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim} [-0.08871851362814162,-0.5157084247243624,0.4267807548167553,
0.7454583329577265,0.2436067770058068,-0.06652244557979875]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 6 e  3, 4, 5.\\
Gli scostamenti tra le coppie 1 e 4, 2 e 5, 3 e 6 non sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda con una differenza che va dallo 0.5 allo 0.7, che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata  n\`e dalla domanda 3 in rapporto con la domanda 1 per una differenza dello 0.5 e n\`e dalla domanda 6 in rapporto con 1; ma per una differenza trascurabile. Ancora una volta mi sembra eccessivo far risalire tali anomalie esclusivamente alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim} [-0.09868401560972781,1.1750817338014279,0.06744526140381923,
-0.004634048490712639,0.731622469327026,-0.2932503126934823]
\end{verbatim}
Appaiono in relazione le domande 2, 3, 5  e 1, 4, 6.\\
Gli scostamenti tra la coppia 1 e 4, 2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda; invece la coppia 3, 6 presenta dei segni con una differenza che \`e nell'ordine dello 0.3.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata nel caso della domanda 1 e 4 in rapporto alla domanda 6; ma  viene poi sfasata dalla domanda 3 con una differenza trascurabile. In questo caso  mi sembra adeguato far risalire tali anomalie esclusivamente alla presenza di valori -1 nel vettore di training. 


\item \begin{verbatim} [-0.18850146670992962,-0.05586297769103521,-0.0701019422477698,
-0.329503465890325,0.20586544889669084,0.4420235238773452]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 3, 4  e 5, 6.\\
Gli scostamenti tra la coppia 1, 4 sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda; invece per le coppia 3, 6 e 2, 5 i segni si presentano con una differenza che va da 0.4 ad 0.7, che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola viene rispettata nel caso della domanda sia 1 che 4 in rapporto alla domanda 3; ma la regola viene poi sfasata anche dalla domanda 6 con una differenza oscilla tra lo 0.6 e lo 0.7 che mi sembra eccessiva se fatta risalire solo alla presenza di valori -1 nel vettore di training.
\end{itemize}

\paragraph{Training set con generazione del profilo di un candidato e calcolo delle probabilit\`a di risposta a 4 neuroni per 1 layer}\mbox{}
\label{Training set con generazione del profilo di un candidato e calcolo delle probabilita di risposta a 4 neuroni per 1 layer}
\\
\noindent
\begin{itemize}
\item \begin{verbatim}[0.0014084113532628062,-0.004834509832051331,0.20465908400406022,
0.6741160798689377,-0.058956549279065115,0.2793587106675337]
\end{verbatim}
Appaiono in relazione le domande 1, 3, 4, 6 e 2, 5\\
Gli scostamenti tra la coppia 2 e 5,  3, 6 e 1, 4 sono consistenti con quelle che sono le relazioni di dipendenza fra le domande.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata nel caso della domanda 1 con una differenza attorno allo 0.2, che mi sembra possa essere fatta risalire alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim}[-0.31386001410295955,-0.009959507832311709,0.25868463437993283,
-0.307419553190237,-0.28353328226534685,0.18854757193486565]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 4, 5 e 3, 6.\\
Gli scostamenti tra le coppie 1 e 4, 2 e 5, 3 e 6 sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata n\`e dalla domanda 3 n\`e dalla domanda 6 con una differenza che oscilla fino allo 0.6. In questo caso mi sembra eccessivo far risalire tali anomalie esclusivamente alla presenza di valori -1 nel vettore di training.

\item \begin{verbatim} [-0.18128927475978635,-0.007801299083368962,0.2076570887277185,
-0.17823375252454843,-0.26524045170035393,-0.3477512471529342]
\end{verbatim}
Appaiono in relazione le domande 1, 2, 4, 5, 6 e 3.\\
Gli scostamenti tra la coppia 1 e 4, 2 e 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda; invece la coppia 3, 6 presenta dei segni con una differenza attorno allo 0.5.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4; la regola viene rispettata nel caso della domanda 3 in rapporto con 1 e 4; la regola negli altri casi viene sfasata per una differenza dello 0.1. In questo caso  mi sembra adeguato far risalire tali anomalie esclusivamente alla presenza di valori -1 nel vettore di training. 


\item \begin{verbatim}[-0.08469366572473985,0.17048135133990547,0.17462198170003868,
0.20231167216006543,0.44015096264819814,0.21540791791735878]
\end{verbatim}
Appaiono in relazione le domande 2, 3, 4, 5, 6 e 1 (a parte).\\
Gli scostamenti tra le coppie 3, 6 e 2, 5 sono consistenti con quelle che sono le relazioni di dipendenza fra le domanda; invece per la coppia 1, 4 i segni si presentano con una differenza inferiore allo 0.2, che mi sembra troppo per venire associata solamente alla presenza di valori -1 all'interno del vettore di training.
Le domande 3 e 6 si dovrebbero presentare con una positivit\`a inferiore rispetto a 1 e 4, la regola non viene rispettata in nessun caso con ma con una differenza che oscilla trascurabile di qualche millesimo.
\end{itemize}

\paragraph{Osservazioni}\mbox{}
\label{Osservazioni su rete a 4 neuroni per 1 layer}
\\\\
\noindent
Rispetto a quanto osservato nei casi precedenti, mi risulta che sia nel caso di utilizzo di training set standard che con profilo di candidato la tecnica dia dei risultati buoni ma inferiori all'impiego di due layers con 2 neuroni ognuno. Se con il set di dati "spuro" potrei sorvolare di pi\`u nelle oscillazioni delle previsioni, questo non vale per il primo set che presenta delle anomalie, anche se ridotte, rispetto a quanto presentato dalla precedente configurazione.
\\\\
\noindent
\textit{Fino ad ora la configurazione di rete che ha dato i maggiori risultati di previsione risulta essere a \textbf{2 layers con 2 neuroni ognuno}.}
Tale conclusione ha senso in quanto il grafo della conoscenza \`e composto da 3 nodi (A, B, C) il quarto neurone rappresenta un nodo con parametri in entrata e in uscita.



